{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9954966,"sourceType":"datasetVersion","datasetId":5988359},{"sourceId":9954973,"sourceType":"datasetVersion","datasetId":5988356},{"sourceId":9955089,"sourceType":"datasetVersion","datasetId":5827927}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/imranbukhari/btcusd-cyclic-period-analysis-with-fft?scriptVersionId=208494085\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Dominant Cyclic Period Analysis in Market Data Using Fast Fourier Transform Methods\n\n# Table of Contents\n* [Importing Libraries and Loading Data](#imports)\n* [Smoothing and Detrending Data](#detrending)\n* [Plotting Original, Smoothed, and Detrended Data](#visualizing-data)\n* [Fast Fourier Transform Analysis](#fft)\n* [Harmonic Factor Analysis](#harmonics)\n* [Conclusion and Interactive Session](#conclusion)\n\n## Introduction - Cyclic Period Analysis\n\nIn this notebook, we will analyze cyclic periods of market data. The aim is to find if there are dominant cyclical periods with stock market datasets; understanding cyclic patterns can be used in various applications such as sales forecasting, stock market analysis, and resource allocation. Our particular use case for this notebook resource is for machine learning (ML), we want to find cyclic periods in our data to create sinusoidal features using those periods to inform a time series forecasting model of these important cycles.\n\nThe first few cells are demonstrations of FFT to illustrate the concept for those unfamiliar before dealing with actual market data, if you are familiar already, please feel free to skip ahead to the 'Importing Libraries and Loading Data' segment, which is where we start our real world analysis.\n\nRather than guessing based on human centric trading timeframes i.e. daily, weekly, monthly, yearly. We would prefer a more mathematically rigorous method to find these periods, we can compare what comes out of the analysis with the aforementioned common sense human timeframes mentioned. If we can extract obvious human-centric periods, we can be sure that the analysis has worked correctly and given us genuine cyclic periods from the data.\n\nIf we are able to extract known periodic cycles, anything else that comes out of the analysis that isn't a known human cycle will be a fantastic bonus, as this would represent a hidden cycle that most other traders will not have access to and giving such data to an ML model will allow it to determine during training, how relevant the hidden cycle may be.","metadata":{}},{"cell_type":"markdown","source":"## Creating Simple Waves and a Composite Wave\n\nIn this section, we import the necessary libraries:\n- **Pandas**: for efficient handling of large datasets.\n- **Numpy**: for numerical operations.\n- **Matplotlib**: to visualize our results.\n- **Scipy**: for the Fast Fourier Transform (FFT).\n\nIn this first cell, we start by generating simple sine waves with specified frequencies.\n\n*     We define two frequencies, 2 Hz and 4 Hz, and use them to create two individual sine waves.\n*     Each wave is then plotted individually to show its profile.\n*     Finally, we create a composite wave by adding the two sine waves together.\n\nThe purpose of this cell is to illustrate how simple waves can combine to form more complex patterns, which is essential for understanding how frequency components interact in time series data.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft, fftfreq\n\n# Function to generate a sine wave for a single frequency\ndef generate_sine_wave(frequency, x):\n    \"\"\"Generate a sine wave for a given frequency.\"\"\"\n    return np.sin(2 * np.pi * frequency * x)\n\n# Function to plot a given wave\ndef plot_wave(x, y, title, xlabel, ylabel):\n    \"\"\"Plot a wave with title and axis labels.\"\"\"\n    plt.figure(figsize=(18, 1.5))\n    plt.plot(x, y)\n    plt.title(title)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.xlim(0, 2)\n    plt.show()\n\n# Define frequencies and x-axis values\nf1 = 2  # Frequency of first sine wave\nf2 = 4  # Frequency of second sine wave\nx = np.linspace(0, 2, 2000)  # The x-axis for our sine wave, between 0 and 2 split into 2000 evenly spaced points\n\n# Generate sine waves using our function\nsine_wave1 = generate_sine_wave(f1, x)\nsine_wave2 = generate_sine_wave(f2, x)\n\n# Composite wave by adding the two sine waves\ncomposite_wave = sine_wave1 + sine_wave2\n\n# Plot each sine wave individually\nplot_wave(x, sine_wave1, f\"Sine Wave 1: Frequency = {f1} Hz\", \"Position (x)\", \"Amplitude\")\nplot_wave(x, sine_wave2, f\"Sine Wave 2: Frequency = {f2} Hz\", \"Position (x)\", \"Amplitude\")\n\n# Plot the composite wave formed by adding the two sine waves\nplot_wave(x, composite_wave, f\"Composite Wave: Sum of {f1} Hz and {f2} Hz Sine Waves\", \"Position (x)\", \"Amplitude\")","metadata":{"execution":{"iopub.status.busy":"2024-11-19T23:21:48.556391Z","iopub.execute_input":"2024-11-19T23:21:48.556937Z","iopub.status.idle":"2024-11-19T23:21:51.684799Z","shell.execute_reply.started":"2024-11-19T23:21:48.556885Z","shell.execute_reply":"2024-11-19T23:21:51.683456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generating Composite Waves with Multiple Frequencies\n\nIn this cell, we extend our concept of composite waves by combining multiple frequencies within a specific range.\n\n*     We use a function to generate composite waves with any number of frequencies, specified by the variable n.\n*     The function takes a range of frequencies (from 5 Hz to 10 Hz) and creates a composite wave by summing sine waves at different frequencies within this range.\n*     We create two composite waves with different numbers of frequencies: one with 2 frequencies and another with 6 frequencies. By combining more frequencies, the profile becomes increasingly complex and begins to show \"beat\" structures as frequencies interfere constructively and destructively. In our analysis of real market data, you'll discover that 'beats' in our profile correspond to market bull runs.\n\nThis cell demonstrates how adding more frequencies to a composite wave increases its complexity. In financial terms, multiple “market cycles” might combine to create intricate price patterns over time.","metadata":{}},{"cell_type":"code","source":"# Function to generate a composite wave with n specified frequencies within the range 5Hz - 10Hz\n# i.e for n=2 it will generate a composite wave of 5Hz and 10Hz and for n=6 it will generate a composite of 5,6,7,8,9,10Hz\ndef generate_composite_wave(n, x):\n    \"\"\"Generate a composite wave by summing n sine waves with specified frequencies up to freq_limit.\"\"\"\n    frequencies = np.linspace(5, 10, n)  # Fixed range for demonstration\n    composite_wave = np.sum([generate_sine_wave(f, x) for f in frequencies], axis=0)\n    return composite_wave, frequencies\n\nn1 = 2  # Number of frequencies for the first composite wave\nn2 = 6  # Number of frequencies for the second composite wave\n\nf_range_start = 5  # Start frequency for the range of frequencies to combine\nf_range_end = 10   # End frequency for the range of frequencies to combine\n\n# Generate and plot a composite wave with n1 frequencies\ncomposite_wave_n1, frequencies_n1 = generate_composite_wave(n1, x)\nplot_wave(x, composite_wave_n1, f\"Composite Wave: Sum of {n1} Frequencies ({f_range_start} to {f_range_end} Hz)\", \"Position (x)\", \"Amplitude\")\n\n# Generate and plot a composite wave with n2 frequencies\ncomposite_wave_n2, frequencies_n2 = generate_composite_wave(n2, x)\nplot_wave(x, composite_wave_n2, f\"Composite Wave: Sum of {n2} Frequencies ({f_range_start} to {f_range_end} Hz)\", \"Position (x)\", \"Amplitude\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-19T23:21:51.687099Z","iopub.execute_input":"2024-11-19T23:21:51.687696Z","iopub.status.idle":"2024-11-19T23:21:52.21136Z","shell.execute_reply.started":"2024-11-19T23:21:51.687646Z","shell.execute_reply":"2024-11-19T23:21:52.210171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Analyzing Frequency Content with FFT\n\nThis cell introduces the Fast Fourier Transform (FFT) to analyze the frequency content of our composite waves.\n\n*     We perform FFT on each composite wave to reveal its frequency components.\n*     The frequency spectrum is plotted, showing the amplitude of each frequency present in the wave.\n*     In the code cell above, we created the waves you saw using 'frequencies = np.linspace(5, 10, n)' so we know the frequencies that made up our waves, simply all integer values from 5-10Hz, in our FFT plot we will plot these frequencies as vertical lines overlaid on top of the FFT output so we can see the frequencies we are expecting from the wave we created.\n\nFFT allows us to decompose complex waves into their constituent frequencies, providing insights into the oscillatory components within the signal. This is useful for analyzing periodic behavior in time series data, such as identifying repeating cycles in market data.","metadata":{}},{"cell_type":"code","source":"# Function to plot frequency spectrum with annotated frequency lines\ndef plot_frequency_spectrum(y, x, frequencies, title, max_frequency=12):\n    \"\"\"Plot the frequency spectrum of a signal with annotated vertical lines for known frequencies.\"\"\"\n    \n    # Perform FFT\n    N = len(x)                                     # The number of samples in the signal. This determines the resolution of the FFT.\n    \n    yf = fft(y)                                    # Perform the FFT (Fast Fourier Transform) on the signal `y`.\n                                                   # This converts the signal from the time domain (amplitude over time)\n                                                   # to the frequency domain (amplitude for each frequency component).\n    \n    xf = fftfreq(N, (x[1] - x[0]))[:N//2]          # Compute the frequencies corresponding to the FFT output.\n                                                   # `N`: Number of samples in the signal.\n                                                   # `(x[1] - x[0])`: Sampling interval, i.e., the time difference between two samples. When we use real data later\n                                                   # we'll convert this from our time resolution to cycles in days i.e. for hours we'll use 1/24 here for 24 samples a day.\n                                                   # Together, these determine the frequency resolution and range.\n                                                   # We use `[:N//2]` to keep only the positive frequencies, as the FFT result\n                                                   # for real signals is symmetric about zero frequency.\n    \n    amplitude = np.abs(yf[:N//2])                  # Compute the magnitude (absolute value) of the FFT result for the positive frequencies.\n                                                   # The FFT produces complex numbers representing both amplitude and phase.\n                                                   # Here, we extract only the amplitude for visualization.\n\n    # Plot frequency spectrum\n    plt.figure(figsize=(18, 2))\n    plt.plot(xf, amplitude)\n    plt.title(title)\n    plt.xlabel(\"Frequency (Hz)\")\n    plt.ylabel(\"Amplitude\")\n    plt.xlim(0, 12)\n\n    # Add vertical lines for each known frequency\n    for f in frequencies:\n        if f <= max_frequency:\n            plt.axvline(x=f, color='red', linestyle='--')\n            plt.text(f, max(amplitude)*0.8, f\"{f:.2f} Hz\", rotation=90, \n                     verticalalignment='center', horizontalalignment='right')\n\n    plt.show()\n\n# Plot frequency spectrum for the two composite waves, plot x-axis restricted to 12 Hz with annotated peaks\nplot_frequency_spectrum(composite_wave_n1, x, frequencies_n1, f\"Frequency Spectrum of Composite Wave with {n1} Frequencies\")\nplot_frequency_spectrum(composite_wave_n2, x, frequencies_n2, f\"Frequency Spectrum of Composite Wave with {n2} Frequencies\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-19T23:21:52.21307Z","iopub.execute_input":"2024-11-19T23:21:52.213521Z","iopub.status.idle":"2024-11-19T23:21:52.822987Z","shell.execute_reply.started":"2024-11-19T23:21:52.213471Z","shell.execute_reply":"2024-11-19T23:21:52.821799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see, the FFT analysis has created a spiked profile with the largest values occurring at the frequencies that make up our composite waves.","metadata":{}},{"cell_type":"markdown","source":"## Handling Trends in Time Series Data\n\nIn this final cell, we explore how a trend can distort frequency analysis and how differencing can help mitigate this effect.\n\n1.     Adding a Trend:\n    * We add a simple linear trend to our second composite waves (the more complex one) to simulate the effect of a trending market, where prices generally move upward or downward over time.\n    * When we perform FFT on this trended wave, we observe that the trend skews the frequency spectrum, making it impossible to isolate the true oscillatory components.\n    \n\n2.     Detrending with Differencing:\n    * We use differencing, a method that calculates the difference between each pair of successive points, to remove the trend.\n    * This method effectively eliminates the low-frequency trend, allowing us to focus on the oscillatory components.\n    * After detrending, we apply FFT again to the differenced wave, and the resulting spectrum reveals the original frequencies with less distortion.\n\nThis process demonstrates that in financial data (or any trending time series), trends can obscure the underlying frequencies and market cycles. By using differencing to detrend the data, we can obtain a clearer frequency spectrum, making it easier to analyze cyclical patterns.","metadata":{}},{"cell_type":"code","source":"# Function to add a linear trend to a wave\ndef add_trend(y, slope=0.1):\n    \"\"\"Add a linear trend to the wave data.\"\"\"\n    trend = slope * np.arange(len(y))\n    return y + trend\n\n# Function to detrend using differencing between subsequent points\ndef detrend_with_differencing(y):\n    \"\"\"Detrend a wave by differencing between subsequent points.\"\"\"\n    return np.diff(y)  # Calculate the difference between subsequent points\n\n# Generate a composite wave with a trend\ntrended_wave = add_trend(2*composite_wave_n2, slope=0.02)\nplot_wave(x, trended_wave, \"Trended Composite Wave\", \"Position (x)\", \"Amplitude\")\n\n# Plot frequency spectrum of the trended wave\nplot_frequency_spectrum(trended_wave, x, frequencies_n2, \"Frequency Spectrum of Trended Composite Wave\", max_frequency=12)\n\n# Detrend the wave by differencing\ndetrended_wave = detrend_with_differencing(trended_wave)\n\n# Adjust x-axis for the detrended wave (since differencing reduces the length by 1)\nx_detrended = x[:-1]\n\n# Plot the detrended wave after differencing\nplot_wave(x_detrended, detrended_wave, \"Detrended Composite Wave (Differencing)\", \"Position (x)\", \"Amplitude\")\n\n# Plot frequency spectrum of the detrended wave\nplot_frequency_spectrum(detrended_wave, x_detrended, frequencies_n2, \"Frequency Spectrum of Detrended Composite Wave (Differencing)\", max_frequency=12)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-19T23:21:52.826462Z","iopub.execute_input":"2024-11-19T23:21:52.8269Z","iopub.status.idle":"2024-11-19T23:21:53.927392Z","shell.execute_reply.started":"2024-11-19T23:21:52.826855Z","shell.execute_reply":"2024-11-19T23:21:53.925955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see from the above, a trending input to FFT will not yield results, however, after differencing we were able to take a trending signal and reform it into a wave that correctly returns the frequencies that made up the original input wave validating the approach.","metadata":{}},{"cell_type":"markdown","source":"## 1. Importing Libraries and Loading Data <a class=\"anchor\" id=\"imports\"></a>\n\nIn this section, we import the necessary libraries:\n- **Pandas**: for efficient handling of large datasets.\n- **Numpy**: for numerical operations.\n- **Matplotlib**: to visualize our results.\n- **Scipy**: for the Fast Fourier Transform (FFT).\n\nWe then load our market data from a pickle file and set the appropriate index using load_data from our util.file_utils module. In this particular analysis, we will be working with BTCUSDT data on multiple timeframes: 1 minute, 1 hour and 1 day. \n\nWe use multiple timeframes to validate against each other i.e. if we get the same dominant frequency showing up in all timeframes, we can be confident that the frequency represents a genuine cyclic market period rather than a potential noise artifact of that timeframe.\n\nNOTE: For the initial demonstration of the techniques we use hourly data at first, you can modify this if you'd like, however, there is a dynamic interactive session at the end of the notebook in which you can modify these values and is a better place to experiment.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft, fftfreq\n    \n# Import the hourly BTCUSD data into a pandas dataframe\ndf = pd.read_csv('/kaggle/input/comprehensive-btcusd-1h-data/BTCUSD_1h_Combined_Index.csv')\n\n# Display the first few rows of the dataframe\ndf.tail()","metadata":{"execution":{"iopub.status.busy":"2024-11-19T23:21:53.929129Z","iopub.execute_input":"2024-11-19T23:21:53.929488Z","iopub.status.idle":"2024-11-19T23:21:54.431911Z","shell.execute_reply.started":"2024-11-19T23:21:53.929453Z","shell.execute_reply":"2024-11-19T23:21:54.430645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Smoothing and Detrending Data <a class=\"anchor\" id=\"detrending\"></a>\n\nIn this section we preprocess our data by detrending using a moving average or differencing.\n\nThere are two methods we use in this session to detrend the data:\n1. By creating a moving average from the original series and subtracting this from the original series, which gives us an oscillating pattern centered around 0 suitable for FFT.\n2. By calculating the difference between successive candle closes, as we did in the initial demonstration.\n\nBoth methods introduce NaN values at the start and end of the dataframe so these must be removed.\n\nThe detrended data contains localized wave packets during periods of high volatility, implying a large number of frequencies make up the overall detrended wave, as you'll see plotted in the next section. We are interested in identifying dominant cyclic periods that occur throughout the dataset and would like to smooth out areas of high volatility, which is the cause of those localized waves. To do this, we apply a log transformation to bring the amplitude of our detrended series within a narrower range, resulting in a continuous wave train rather than localized packets.\n\nGiven that logs can only be taken within the range x>=1, we must take the absolute value of our detrended data and add 1. This essentially shifts our pattern up by 1 whilst creating frequency components twice the frequencies of ones that already exist i.e. if we take the absolute value of a sine wave, we double the frequency of periodicity, whilst keeping the original frequency as a second harmonic. We can restore the parity to our series by multiplying our detrended series by the sign content of the original series, whilst this appears to make more sense, the results are much better without doing this.\n\nA more consistent wave train amplitude will contain fewer component frequencies and hopefully they will be the frequencies we are looking for. These ideas can be quite abstract, so to get a better idea of what we will be working with, we will plot all of these series in our next section.","metadata":{}},{"cell_type":"code","source":"samples_per_day = 24         # Samples per day is required to calibrate the FFT frequency plot so that our frequency output is in cycles per day\nma_window_size_in_days = 14  # The size of the moving average window\ndetrend = 'differencing'     # The method to detrend, for demo purposes leave as differencing until the end\npreserve_parity = 'no'       # After log detrending we wind up with all positive values in our detrended series, this restores negatives where they were before\nfactor = 500000000000000000  # Factor to adjust the amplitude of the Detrended wave, this helps stabilize the log operation by attenuating very low values and \n                             # does not affect the FFT frequencies but will make them stand out more, adjust to see how the results affected\n    \nwindow_size = samples_per_day * ma_window_size_in_days          \n\n# Calculate the moving average of our close series\ndf['Smoothed'] = df['Close'].rolling(window=window_size, center=True).mean()\n\n# Detrend the Close series using either moving average or differencing\nif detrend == 'moving_average':\n    df['Detrended'] = df['Close'] - df['Smoothed']\n    df.dropna(subset=['Detrended'], inplace=True)\nelif detrend == 'differencing':\n    df['Detrended'] = df['Close'].diff()\n    df.dropna(subset=['Detrended'], inplace=True)\n\n# Restore the parity of the Close series after putting through the log operation\nif preserve_parity == 'yes':\n    df['Log_Detrended'] = np.log((df['Detrended']*factor).abs() + 1) * np.sign(df['Detrended'])\nelse:\n    df['Log_Detrended'] = np.log((df['Detrended']*factor).abs() + 1)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T23:21:54.433381Z","iopub.execute_input":"2024-11-19T23:21:54.433794Z","iopub.status.idle":"2024-11-19T23:21:54.472935Z","shell.execute_reply.started":"2024-11-19T23:21:54.43375Z","shell.execute_reply":"2024-11-19T23:21:54.471443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Plotting Original, Smoothed, and Detrended Data <a class=\"anchor\" id=\"visualizing-data\"></a>\n\nIn this section, we visualize the original data, smoothed data, and detrended data. \n\nThis helps us understand the transformations applied to the dataset and how the detrending and log transformation have modified the original series. It also let's us visually inspect how the series is modified via each step in section 2 by plotting the data all together in one plot temporally in sync.","metadata":{}},{"cell_type":"code","source":"# Plot the original, smoothed, and detrended data\nfig, axs = plt.subplots(2, 1, figsize=(18, 12))\naxs[0].plot(df['Close'], label='Original Data')\naxs[0].plot(df['Smoothed'], label='Smoothed Data', linestyle='--')\naxs[0].plot(df['Detrended'], label='Detrended Data', linestyle='-.')\naxs[0].legend()\naxs[0].set_title('Original, Smoothed, and Detrended Data')\n\n# Plot the log of the detrended data\naxs[1].plot(df['Log_Detrended'], label='Log of Detrended Data', color='r')\naxs[1].legend()\naxs[1].set_title('Log of Detrended Data')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-19T23:21:54.474522Z","iopub.execute_input":"2024-11-19T23:21:54.475061Z","iopub.status.idle":"2024-11-19T23:21:56.486985Z","shell.execute_reply.started":"2024-11-19T23:21:54.475026Z","shell.execute_reply":"2024-11-19T23:21:56.485833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see from the above, we have a moving average (smoothed data) of our closing price plotted alongside the BTCUSD closing price (original data). For the moving average detrending, we subtract this average from our data to give us what looks like a sound wave with localized waves below it (detrended data) and we squeeze that through a log filter so that we map to a narrower range of outputs giving us a more spread out wave train and ironing out the localized packets. For the differencing method, we simply calculate the difference between subsequent close values and again apply the log filter.\n\nThe cyclic features will be preserved in this transformation as we haven't changed the frequencies, only the amplitude in this log mapping.","metadata":{}},{"cell_type":"markdown","source":"## 4. FFT Analysis <a class=\"anchor\" id=\"fft\"></a>\n\nIn this section, we use the core mathematical technique of this analysis, the Fast Fourier Transform (FFT), to find the frequencies of the individual pure sine waves that make up our detrended log series. \n\nNote that we use the parameter 'samples_per_day' which gives a frequency bin output (generated by fftfreq) in cycles per day. There are a lot of low amplitude noise frequencies due to the random fluctuations inherent in market data, so we set a frequency noise threshold based on the mean spectral magnitude and its standard deviations to identify dominant frequencies, we also filter our negative frequencies as these are not relevant to this analysis. We extract all dominant frequencies that exceed our threshold and convert these frequencies into periods (in days) by taking the inverse. This helps us understand the cyclical nature of the data in terms of days per cycle.\n\nUsing lower timeframe data inherently has more noise, which means many more frequencies in our fft spectrum, the noise frequency threshold should be adjusted so we don't catch this noise. You can experiment with different values to capture more or less, the noise threshold is up to you. Note that the noise frequency threshold is controlled by multiplying standard_deviations_from_mean by a factor you can set. Smaller timeframes will require higher values, through experimentation, I've found minute, hourly, daily to work well with values of 16, 2, 0.3 respectively using the differencing method without parity. These values extract around 20 dominant frequencies that make up our detrended log series for each timeframe. \n\nWe visualize the output of our FFT analysis by plotting the full frequency range output and our noise filtered output. This visualization demonstrates where the identified periods come from and what exactly is being filtered.\n","metadata":{}},{"cell_type":"code","source":"# Changing this parameter changes which dominant frequencies we pick out\n# Lowering filters less points, too low picks up fft noise\nstandard_deviations_from_mean = 0.7\n\n# Compute the FFT of the log detrended data\ntotal_samples = len(df['Log_Detrended'])\ndf['frequency_amplitude'] = np.abs(fft(df['Log_Detrended'].values))\ndf['frequency_spectrum'] = fftfreq(total_samples, 1/samples_per_day)\n\n# Calculate the mean and standard deviation of the spectral magnitude\namplitude_mean = df['frequency_amplitude'].mean()\namplitude_standard_deviation = df['frequency_amplitude'].std()\nprint(f\"Mean of spectral magnitude: {amplitude_mean}, Standard deviation of spectral magnitude: {amplitude_standard_deviation}\")\n\n# Determine the dominant frequencies and their amplitudes based on a threshold determined standard deviations from the mean\n# We also set a condition to filter out negative frequencies\nthreshold = standard_deviations_from_mean * amplitude_standard_deviation + amplitude_mean\ndominantAmpCheck = df['frequency_amplitude'] > threshold\npositiveFreqCheck = df['frequency_spectrum'] > 0\n\n# Filter for the dominant amplitudes and frequencies using our predefined check conditions\n# Take the inverse of this frequency to determine the period in days for our dominant cycles\ndominantAmp = df[dominantAmpCheck & positiveFreqCheck]['frequency_amplitude']\ndominantFreq = df[dominantAmpCheck & positiveFreqCheck]['frequency_spectrum']\ndominantPeriods = 1 / dominantFreq\n\n# Plot the frequency spectrum and the dominant frequencies\nfig, axs = plt.subplots(1, 2, figsize=(18, 6))\n\n# Plot only the positive frequency spectrum\npositive_frequency_spectrum = df['frequency_spectrum'][df['frequency_spectrum'] > 0]\npositive_frequency_amplitude = df['frequency_amplitude'][df['frequency_spectrum'] > 0]\naxs[0].plot(positive_frequency_spectrum, positive_frequency_amplitude, '.')\naxs[0].set_title('Positive Frequency Spectrum')\naxs[0].set_xlabel('Frequency (cycles per day)')\naxs[0].set_ylabel('Amplitude')\n# Highlight dominant frequencies\naxs[0].plot(dominantFreq, dominantAmp, 'ro')\n\n# Add vertical lines and labels for daily, weekly, monthly, and yearly frequencies\nfrequencies = [1, 1/7, 1/30, 1/365]\nlabels = ['Daily', 'Weekly', 'Monthly', 'Yearly']\nfor freq, label in zip(frequencies, labels):\n    axs[1].axvline(x=freq, color='r', linestyle='--', linewidth=0.5)\n    axs[1].text(freq, axs[1].get_ylim()[1], label, rotation=90, verticalalignment='top', color='r')\n\naxs[1].plot(dominantFreq, dominantAmp, '.')\naxs[1].set_title('Dominant Frequencies vs Amplitudes')\naxs[1].set_xlabel('Frequency (cycles per day)')\naxs[1].set_ylabel('Amplitude')\n\nplt.tight_layout()\nplt.show()\n\ndef group_by_lcf(series, tolerance=0.2):\n    \"\"\"\n    Groups periods in a series based on lowest common frequency (LCF) or multiples.\n    Periods less than 1.5 are placed in their own group.\n    \"\"\"\n    groups = []\n    small_periods = []\n\n    for period in series:\n        added = False\n        \n        # If the period is less than 1.5, add it to small_periods group and skip further checks\n        if period < 1.5:\n            small_periods.append(period)\n            continue\n\n        for group in groups:\n            base_period = group[0]\n            multiplier = 1\n\n            # Check if period matches any multiple of the base period within tolerance\n            while base_period * multiplier <= period * (1 + tolerance):\n                if abs(period - base_period * multiplier) <= tolerance * multiplier:\n                    group.append(period)\n                    added = True\n                    break\n                multiplier += 1\n            \n            if added:\n                break\n\n        if not added:\n            groups.append([period])\n\n    # Format groups with six decimal precision\n    formatted_groups = [f\"{', '.join(f'{val:.6f}' for val in group)}\" for group in groups]\n    \n    # Add small periods group if there are any small periods\n    if small_periods:\n        formatted_small_periods = f\"{', '.join(f'{val:.6f}' for val in small_periods)}\"\n        formatted_groups.append(formatted_small_periods)\n    \n    return formatted_groups\n\n# Reverse dominant periods and group with harmonics alongside a specified tolerance\ndfr = dominantPeriods[::-1]\ngrouped_periods = group_by_lcf(dfr, tolerance=0.02)\n\n# Display grouped periods\nprint(\"\\nDominant Frequencies grouped as Harmonics (multiples of the lowest frequencies in the group):\")\nfor i, group in enumerate(grouped_periods, 1):\n    print(f\"Group {i}: {group}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-19T23:21:56.48863Z","iopub.execute_input":"2024-11-19T23:21:56.489057Z","iopub.status.idle":"2024-11-19T23:21:57.325216Z","shell.execute_reply.started":"2024-11-19T23:21:56.48902Z","shell.execute_reply":"2024-11-19T23:21:57.323994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Conclusion and Interactive Session<a class=\"anchor\" id=\"conclusion\"></a>\n\nUsing minute, hourly, and daily timeframe data, we observe that many of the same periods appear across all timeframes, confirming the robustness of our analysis. Expected cycles, such as 1-day (daily) and 7-day (weekly) intervals, show up consistently, verifying that our method accurately detects well-known trading patterns. The most prominent cycles are half daily, daily, half-weekly and weekly. Alongside these, more unique cycles emerged prominently, particularly the 61.89-day (two-month) frequency. This base frequency has harmonics at intervals near 123.98 days (quarterly), 185.70 days (six months), and 371.41 days (annual).\n\nThe larger cycles above are slightly shifted from the expected intervals, suggesting that while some market participants may still trade on traditional long-term timeframes (e.g., 182.5 and 365 days), they are being slightly overpowered by other participants who trade on shorter, more regular cycles, like 31-day monthly or quarterly schedules. This two-month frequency likely represents a foundational rhythm impacting broader cyclical patterns in the market.\n\nLuckily we have also discovered many unknown cyclic periods that cannot be tied to known human patterns... This is very interesting and the type of information/data we can use to give us an edge over other traders and certainly useful cyclic information to user as a feature in machine learning models as we'll be doing in other notebooks. One limitation of the above analysis is trusting the much larger cycles, when performing FFT on noisy data, you can always expect that we get a spike in frequencies towards the lower end of the spectrum, as we also saw on the trending mock data in our introduction, going beyond the annual frequency of 371.41 days will likely yield erroneous results. As this particular frequency was a harmonic of the half-week, weekly, two-month base frequencies, we can accept this final frequency as a legitimate cutoff before we should expect more erroneous results.\n\nThe method above can be used on any dataset, the approach is logically sound and not limited to BTCUSD data.\n\nBelow is a dynamic interactive session that you can modify key parameters within using all the same steps above. The section below has been optimized for live use and plotting. There are instructions included at below the interactive output for what each option modifies.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft, fftfreq\nimport ipywidgets as widgets\nfrom ipywidgets import interactive, HBox, VBox\nfrom matplotlib.gridspec import GridSpec\nfrom typing import Tuple, Optional\nimport warnings\n\n# Ignore UserWarnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# Define a dictionary for samples per day based on the timeframe\ntimeframe_dict = {\n    '1m': 1440,\n    '1h': 24,\n    '1d': 1\n}\n\n# Function to load and preprocess data\ndef load_and_preprocess_data(timeframe: str, ma_window_size_in_days: int, detrend: str) -> Tuple[Optional[pd.DataFrame], Optional[int]]:\n    samples_per_day = timeframe_dict.get(timeframe, None)\n    df = pd.read_csv(f'/kaggle/input/comprehensive-btcusd-{timeframe}-data/BTCUSD_{timeframe}_Combined_Index.csv')\n    if df is None:\n        return None, None\n\n    window_size = samples_per_day * ma_window_size_in_days\n    df['Smoothed'] = df['Close'].rolling(window=window_size, center=True).mean()\n\n    if detrend == 'moving_average':\n        df['Detrended'] = df['Close'] - df['Smoothed']\n        df.dropna(subset=['Detrended'], inplace=True)\n    elif detrend == 'differencing':\n        df['Detrended'] = df['Close'].diff()\n        df.dropna(subset=['Detrended'], inplace=True)\n\n    return df, samples_per_day\n\n# Function to compute log detrended values\ndef compute_log_detrended(df: pd.DataFrame, preserve_parity: str) -> pd.DataFrame:\n    if preserve_parity == 'yes':\n        df['Log_Detrended'] = np.log((df['Detrended']*factor).abs() + 1) * np.sign(df['Detrended'])\n    else:\n        df['Log_Detrended'] = np.log((df['Detrended']*factor).abs() + 1)\n    return df\n\n# Function to perform FFT\ndef perform_fft(df: pd.DataFrame, samples_per_day: int, resolution: int) -> Tuple[np.ndarray, np.ndarray]:\n    N = resolution\n    padded_length = len(df['Log_Detrended']) * N\n    padded_log_detrended = np.pad(df['Log_Detrended'].values, (0, padded_length - len(df['Log_Detrended'])), 'constant')\n\n    total_samples = len(padded_log_detrended)\n    frequency_amplitude = np.abs(fft(padded_log_detrended))\n    frequency_spectrum = fftfreq(total_samples, 1/samples_per_day)\n    \n    return frequency_amplitude, frequency_spectrum\n\n# Function to identify dominant frequencies\ndef identify_dominant_frequencies(frequency_amplitude: np.ndarray, frequency_spectrum: np.ndarray, standard_deviations_from_mean: float) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    amplitude_mean = frequency_amplitude.mean()\n    amplitude_standard_deviation = frequency_amplitude.std()\n\n    threshold = standard_deviations_from_mean * amplitude_standard_deviation + amplitude_mean\n    dominantAmpCheck = frequency_amplitude > threshold\n    positiveFreqCheck = frequency_spectrum > 0\n\n    dominantAmp = frequency_amplitude[dominantAmpCheck & positiveFreqCheck]\n    dominantFreq = frequency_spectrum[dominantAmpCheck & positiveFreqCheck]\n    dominantPeriods = 1 / dominantFreq\n\n    return dominantAmp, dominantFreq, dominantPeriods\n\n# Function to plot data\ndef plot_data(df: pd.DataFrame, positive_freq_spectrum: np.ndarray, positive_freq_amplitude: np.ndarray, dominantFreq: np.ndarray, dominantAmp: np.ndarray, dominantPeriods: np.ndarray, show_labels: str, lower_xlim: float, upper_xlim: float, max_amplitude_in_range: float) -> None:\n    fig = plt.figure(figsize=(18, 8))\n    gs = GridSpec(3, 2, height_ratios=[1, 1, 3])\n\n    ax1 = plt.subplot(gs[0, :])\n    ax1.plot(df['Close'], label='Original Data')\n    ax1.plot(df['Smoothed'], label='Smoothed Data', linestyle='--')\n    ax1.plot(df['Detrended'], label='Detrended Data', linestyle='-.')\n    ax1.legend()\n    ax1.set_title('Original, Smoothed, and Detrended Data')\n\n    ax2 = plt.subplot(gs[1, :])\n    ax2.plot(df['Log_Detrended'], label='Log of Detrended Data', color='r')\n    ax2.legend()\n    ax2.set_title('Log of Detrended Data')\n\n    ax3 = plt.subplot(gs[2, 0])\n    ax3.plot(positive_freq_spectrum, positive_freq_amplitude, '.', label='Full Spectrum')\n    if show_labels == 'yes':\n        ax3.plot(dominantFreq, dominantAmp, '.', label='Dominant Frequencies, labelled by period')\n        for i in range(len(dominantFreq)):\n            ax3.annotate(f'{dominantPeriods[i]:.2f}', (dominantFreq[i], dominantAmp[i]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n\n    for freq, label in zip([1, 1/7, 1/30, 1/365], ['daily', 'weekly', 'monthly', 'yearly']):\n        ax3.axvline(x=freq, color='red', linestyle='--', linewidth=1)\n        ax3.text(freq, ax3.get_ylim()[0] + (ax3.get_ylim()[1] - ax3.get_ylim()[0]) / 2, label, rotation=90, verticalalignment='center')\n\n    ax3.set_xlim(0, 1.1)\n    ax3.legend()\n    ax3.set_title('Frequency Spectrum and Dominant Frequencies')\n    ax3.set_xlabel('Frequency (cycles per day)')\n    ax3.set_ylabel('Amplitude')\n\n    ax4 = plt.subplot(gs[2, 1])\n    ax4.plot(positive_freq_spectrum, positive_freq_amplitude, '.', label='Full Spectrum')\n    ax4.set_ylim(0, max_amplitude_in_range)\n    ax4.set_xlim(lower_xlim, upper_xlim)\n    if show_labels == 'yes':\n        ax4.plot(dominantFreq, dominantAmp, '.', label='Dominant Frequencies, labelled by period')\n        for i in range(len(dominantFreq)):\n            ax4.annotate(f'{dominantPeriods[i]:.2f}', (dominantFreq[i], dominantAmp[i]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n\n    for freq, label in zip([1, 1/7, 1/30, 1/365], ['daily', 'weekly', 'monthly', 'yearly']):\n        if lower_xlim < freq < upper_xlim:\n            ax4.axvline(x=freq, color='red', linestyle='--', linewidth=1)\n            ax4.text(freq, ax4.get_ylim()[0] + (ax4.get_ylim()[1] - ax4.get_ylim()[0]) / 2, label, rotation=90, verticalalignment='center')\n        \n    ax4.legend()\n    ax4.set_title('Frequency Spectrum (adjustable x-limit) and Dominant Frequencies')\n    ax4.set_xlabel('Frequency (cycles per day)')\n    ax4.set_ylabel('Amplitude')\n\n    plt.tight_layout()\n    plt.show()\n\n# Function to update the plots based on adjustable parameters and selected timeframe\ndef update_plots(timeframe: str, ma_window_size_in_days: int, standard_deviations_from_mean: float, detrend: str, preserve_parity: str, show_labels: str, resolution: int, lower_xlim: float, upper_xlim: float) -> None:\n    loading_label.value = \"Loading...\"\n    df, samples_per_day = load_and_preprocess_data(timeframe, ma_window_size_in_days, detrend)\n    if df is None:\n        loading_label.value = \"\"\n        return\n\n    df = compute_log_detrended(df, preserve_parity)\n    frequency_amplitude, frequency_spectrum = perform_fft(df, samples_per_day, resolution)\n    dominantAmp, dominantFreq, dominantPeriods = identify_dominant_frequencies(frequency_amplitude, frequency_spectrum, standard_deviations_from_mean)\n\n    positive_freq_spectrum = frequency_spectrum[frequency_spectrum > 0]\n    positive_freq_amplitude = frequency_amplitude[frequency_spectrum > 0]\n\n    in_range_amplitudes = positive_freq_amplitude[(positive_freq_spectrum >= lower_xlim) & (positive_freq_spectrum <= upper_xlim)]\n    max_amplitude_in_range = in_range_amplitudes.max()*1.05 if len(in_range_amplitudes) > 0 else 0\n\n    plot_data(df, positive_freq_spectrum, positive_freq_amplitude, dominantFreq, dominantAmp, dominantPeriods, show_labels, lower_xlim, upper_xlim, max_amplitude_in_range)\n    loading_label.value = \"\"\n\n# Function to update the bounds of the sliders\ndef update_xlim_ranges(*args) -> None:\n    lower_xlim = lower_xlim_slider.value\n    upper_xlim_slider.min = lower_xlim + 1e-2\n    if upper_xlim_slider.value < upper_xlim_slider.min:\n        upper_xlim_slider.value = upper_xlim_slider.min\n    upper_xlim = upper_xlim_slider.value\n    lower_xlim_slider.max = upper_xlim - 1e-2\n    if lower_xlim_slider.value > lower_xlim_slider.max:\n        lower_xlim_slider.value = lower_xlim_slider.max\n\n# Function to toggle visibility of widgets based on other widget values\ndef toggle_visibility(*args) -> None:\n    if detrend_dropdown.value == 'differencing':\n        ma_window_slider.layout.display = 'none'\n    else:\n        ma_window_slider.layout.display = ''\n    \n    if labels_dropdown.value == 'no':\n        std_dev_slider.layout.display = 'none'\n    else:\n        std_dev_slider.layout.display = ''\n\n# Create interactive sliders, dropdowns, and timeframe selector for the parameters\ntimeframe_dropdown = widgets.Dropdown(\n    options=['1m', '1h', '1d'],\n    value='1h',\n    description='Timeframe',\n    style={'description_width': 'initial'}\n)\nlabels_dropdown = widgets.Dropdown(\n    options=['yes', 'no'],\n    value='yes',\n    description='Labels',\n    style={'description_width': 'initial'}\n)\nma_window_slider = widgets.IntSlider(min=2, max=720, step=1, value=7, description='MA Window (days)', style= {'description_width': 'initial'}, continuous_update=False)\nstd_dev_slider = widgets.FloatSlider(min=0.1, max=30, step=0.1, value=2, description='Std Dev from Mean', style= {'description_width': 'initial'}, continuous_update=False)\ndetrend_dropdown = widgets.Dropdown(\n    options=['moving_average', 'differencing'],\n    value='differencing',\n    description='Detrend Method',\n    style= {'description_width': 'initial'}\n)\nparity_dropdown = widgets.Dropdown(\n    options=['yes', 'no'],\n    value='no',\n    description='Preserve Parity',\n    style= {'description_width': 'initial'}\n)\nresolution_dropdown = widgets.Dropdown(\n    options=[1, 2, 5, 10],\n    value=1,\n    description='Resolution',\n    style={'description_width': 'initial'}\n)\nlower_xlim_slider = widgets.FloatSlider(min=0, max=1.1, step=1/10000, value=0, description='Lower xlim', style= {'description_width': 'initial'}, continuous_update=False)\nupper_xlim_slider = widgets.FloatSlider(min=0, max=1.1, step=1/10000, value=1/6.8, description='Upper xlim', style= {'description_width': 'initial'}, continuous_update=False)\n\n# Adjust the width and height of the sliders and dropdown using the layout attribute\ntimeframe_dropdown.layout = widgets.Layout()\nlabels_dropdown.layout = widgets.Layout()\nma_window_slider.layout = widgets.Layout(width='50%')\nstd_dev_slider.layout = widgets.Layout(width='50%')\ndetrend_dropdown.layout = widgets.Layout(width='34%')\nparity_dropdown.layout = widgets.Layout(width='34%')\nresolution_dropdown.layout = widgets.Layout(width='34%')\nlower_xlim_slider.layout = widgets.Layout(width='50%')\nupper_xlim_slider.layout = widgets.Layout(width='50%')\n\ndef attach_observers():\n    lower_xlim_slider.observe(update_xlim_ranges, names='value')\n    upper_xlim_slider.observe(update_xlim_ranges, names='value')\n    detrend_dropdown.observe(toggle_visibility, names='value')\n    labels_dropdown.observe(toggle_visibility, names='value')\n\n# Initialize visibility, upper and lower xlim value based on the default values\ntoggle_visibility()\nupdate_xlim_ranges()\nattach_observers()\n\n# Loading label\nloading_label = widgets.Label(value=\"\")\n\n# Organize the widgets in the desired layout\nrow1 = HBox([timeframe_dropdown, labels_dropdown, detrend_dropdown, parity_dropdown, resolution_dropdown])\nrow2 = HBox([lower_xlim_slider, upper_xlim_slider])\nrow3 = HBox([std_dev_slider, ma_window_slider])\nwidget_box = VBox([row1, row2, row3, loading_label])\n\n# Create the interactive plot without displaying it\ninteractive_plot = interactive(update_plots, timeframe=timeframe_dropdown, ma_window_size_in_days=ma_window_slider, standard_deviations_from_mean=std_dev_slider, detrend=detrend_dropdown, preserve_parity=parity_dropdown, show_labels=labels_dropdown, resolution=resolution_dropdown, lower_xlim=lower_xlim_slider, upper_xlim=upper_xlim_slider)\noutput = interactive_plot.children[-1]\noutput.layout.height = '100%'\n\n# Display the widgets and the interactive plot\ndisplay(widget_box, output)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T23:21:57.327382Z","iopub.execute_input":"2024-11-19T23:21:57.327941Z","iopub.status.idle":"2024-11-19T23:21:57.565614Z","shell.execute_reply.started":"2024-11-19T23:21:57.327832Z","shell.execute_reply":"2024-11-19T23:21:57.562682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# User Guide: Interactive Dynamic Session for Analyzing BTCUSD Market Data\n\nThis interactive session allows you to explore FFT-based frequency analysis of BTCUSD market data dynamically, to start toggle the labels off. Below are instructions for using each control element:\n\n1. Timeframe Selection    \n* Choose the timeframe of the data to analyze.\n* Effect: Adjusts the resolution of the analysis, with higher granularity for smaller timeframes.\n\n2. Labels\n* Description: Toggle whether dominant frequencies are labeled on the frequency spectrum. \n* **NOTE:** When standard deviations from mean is too low, this will plot a huge amount of labels and slow the plot rendering.\n  * yes: Display frequency periods as labels on the plot.\n  * no: Hide the labels for a cleaner plot.\n\n3. Detrend Method\n* Description: Select the method for detrending the data.\n    * moving_average: Subtracts a moving average to remove trends.\n    * differencing: Uses first-order differencing to detrend.\n\n4. Preserve Parity\n* Description: Decide whether to preserve the sign of detrended values when computing the logarithm.\n    * yes: Preserves the sign of the data after putting the detrended data through the log operation.\n    * no: Ignores the sign, using absolute values.\n\n5. Moving Average Window (days)\n* Description: Specify the size of the moving average window in days. \n* **NOTE:** Only available when moving_average is selected as the detrend method.\n    * Range: 2 to 720 days.\n\n6. Standard Deviations from Mean\n* Description: Set the threshold for identifying dominant frequencies based on their amplitudes. Larger values filter out more frequencies, showing only the most prominent ones. \n* **NOTE:** This is only available with labels on.\n    * Range: 0.1 to 30.\n\n7. Resolution\n* Description: Choose the padding factor for FFT resolution. Higher values add zero-padding, increasing the frequency resolution allowing us to see a more detailed profile, however, frequency peaks are reduced.\n    * Options: 1, 2, 5, 10.\n\n8. Upper/Lower x-limit\n* Description: Set the upper/lower limit of the x-axis for zoomed in plot in the bottom right of the session to allow inspection of any frequency region with a zoomed in perspective.\n    * Range: 0 to 1.1.\n\nEnjoy analyzing the data!","metadata":{}}]}